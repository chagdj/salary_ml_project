# ğŸš€ Salary Prediction Using Machine Learning

## ğŸ“Œ Project Overview
This project aims to predict salary ranges based on various job-related features using machine learning models. The models used include **ğŸŒ² Random Forest, ğŸš€ XGBoost, âš¡ LightGBM, and ğŸ¤– SVM**, with hyperparameter tuning and **ğŸ“Š SMOTE** to handle class imbalances. 

## ğŸ”¢ Features and Encoding
The dataset contains the following key features:
- ğŸ“† **Years of Experience** (binned every 3 years)
- ğŸ‡©ğŸ‡ª **Years of Experience in Germany** (binned every 2 years)
- ğŸ“Š **Seniority Level** (Ordinal encoding: Junior, Mid-level, Senior, etc.)
- ğŸ¢ **Company Size** (Categorical encoding: 0-50, 50-100, etc.)
- ğŸ¤– **AI Use** (Binary: Yes/No)
- ğŸ“ **Position and City** (One-hot encoded)
- ğŸ’° **Salary Range** (Binned and encoded for classification)

## ğŸ”§ Data Preprocessing
1. ğŸ›  **Feature Engineering**: Encoding categorical variables, binning years of experience, and handling missing values.
2. ğŸ“ **Scaling**: Standardizing numerical features for models like SVM and Logistic Regression.
3. âš–ï¸ **Class Balancing**: Using **SMOTE** to oversample underrepresented salary ranges.

## ğŸ‹ï¸â€â™‚ï¸ Model Training
### **ğŸ§  Models Implemented**:
- ğŸŒ² **Random Forest**
- ğŸš€ **XGBoost**
- âš¡ **LightGBM**
- ğŸ¤– **SVM**
- ğŸ” **Logistic Regression** (Baseline)

### **ğŸ›  Hyperparameter Tuning**:
- ğŸ¯ **GridSearchCV**: Optimized hyperparameters for better performance.
- ğŸ”„ **Cross-validation**: Used K-Fold cross-validation for robust evaluation.

## ğŸ“Š Model Evaluation
- âœ… **Accuracy**: Measures the overall correctness of predictions.
- ğŸ§© **Confusion Matrix**: Evaluates the modelâ€™s classification performance for different salary classes.
- ğŸ¯ **Precision, Recall, F1-score**: Helps assess model strengths and weaknesses per salary class.

## ğŸ† Key Results
- Best performing model: **[ğŸ… Random Forest]** with **[ğŸ“ˆ 55%]**.
- Accuracy improved by **[ğŸš€ 14%]** after feature engineering and SMOTE.
- Model struggles with **salary class 2**, requiring further balancing strategies.

## ğŸš€ Improvements & Next Steps
- âš–ï¸ **Better Handling of Class Imbalances**: Adjust SMOTE strategy.
- ğŸ¯ **Feature Selection**: Reduce less significant features for better generalization.
- ğŸ”§ **Hyperparameter Optimization**: Fine-tune learning rate and regularization parameters.
- ğŸ¤ **Try Ensemble Learning**: Combining multiple models for better performance.

## â–¶ï¸ How to Run the Project
### **ğŸ“Œ Requirements**:
Install dependencies using:
```bash
pip install -r requirements.txt
```
### **ğŸš€ Run the Model**:
```bash
python train_model.py
```




